{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
    "\n",
    "The `textFile` function returns data in strings. This should work fine for this lab.\n",
    "\n",
    "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
    "```\n",
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines() )\n",
    "```\n",
    "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
    "rddPatents = sc.textFile(\"apat63_99.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"CITING\",\"CITED\"',\n",
       " '3858241,956203',\n",
       " '3858241,1324234',\n",
       " '3858241,3398406',\n",
       " '3858241,3557384']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCitations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"',\n",
       " '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,',\n",
       " '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,',\n",
       " '3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,',\n",
       " '3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddPatents.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for parsing CSV data\n",
    "def parse_citation_line(line):\n",
    "    \"\"\"Parse citation line and return (citing, cited) tuple\"\"\"\n",
    "    parts = line.split(',')\n",
    "    if len(parts) >= 2:\n",
    "        try:\n",
    "            citing = int(parts[0].strip('\"'))\n",
    "            cited = int(parts[1].strip('\"'))\n",
    "            return (citing, cited)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def parse_patent_line(line):\n",
    "    \"\"\"Parse patent line and return (patent_id, (state, full_data)) tuple\"\"\"\n",
    "    parts = line.split(',')\n",
    "    if len(parts) >= 6:\n",
    "        try:\n",
    "            patent_id = int(parts[0].strip('\"'))\n",
    "            country = parts[4].strip('\"')\n",
    "            state = parts[5].strip('\"')\n",
    "            \n",
    "            # Only include US patents with state information\n",
    "            if country == 'US' and state and state != '':\n",
    "                return (patent_id, (state, parts))\n",
    "        except (ValueError, IndexError):\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Process the data with sampling option\n",
    "def solve_patent_problem(use_sample=True, sample_fraction=0.25):\n",
    "    \"\"\"\n",
    "    Solve the patent citation problem using RDD API\n",
    "    \n",
    "    Args:\n",
    "        use_sample: If True, use a sample of the data for faster processing\n",
    "        sample_fraction: Fraction of data to sample (default 0.05 = 5%)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (result_dict, top_10_list, full_citation_data_rdd) for verification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load and optionally sample the data\n",
    "    if use_sample:\n",
    "        print(f\"Using {sample_fraction*100}% sample of the data...\")\n",
    "        citations_rdd = rddCitations.sample(False, sample_fraction, seed=42)\n",
    "        patents_rdd = rddPatents.sample(False, sample_fraction, seed=42)\n",
    "    else:\n",
    "        print(\"Using full dataset...\")\n",
    "        citations_rdd = rddCitations\n",
    "        patents_rdd = rddPatents\n",
    "    \n",
    "    # Remove headers and parse citations\n",
    "    citations_header = citations_rdd.first()\n",
    "    citations_parsed = (citations_rdd\n",
    "                       .filter(lambda line: line != citations_header)\n",
    "                       .map(parse_citation_line)\n",
    "                       .filter(lambda x: x is not None))\n",
    "    \n",
    "    print(f\"Parsed citations: {citations_parsed.count()}\")\n",
    "    citations_parsed.cache()\n",
    "    \n",
    "    # Remove headers and parse patents (only US patents with states)\n",
    "    patents_header = patents_rdd.first()\n",
    "    patents_parsed = (patents_rdd\n",
    "                     .filter(lambda line: line != patents_header)\n",
    "                     .map(parse_patent_line)\n",
    "                     .filter(lambda x: x is not None))\n",
    "    \n",
    "    print(f\"US patents with state info: {patents_parsed.count()}\")\n",
    "    patents_parsed.cache()\n",
    "    \n",
    "    # Create lookup for patent states: (patent_id, state)\n",
    "    patent_states = patents_parsed.mapValues(lambda x: x[0])  # Extract just the state\n",
    "    patent_states.cache()\n",
    "    \n",
    "    print(\"Sample patent states:\")\n",
    "    print(patent_states.take(5))\n",
    "    \n",
    "    # Join citations with cited patent states\n",
    "    # Transform citations to (cited_patent, citing_patent) for join\n",
    "    citations_for_cited_join = citations_parsed.map(lambda x: (x[1], x[0]))\n",
    "    \n",
    "    # Join with patent states to get cited patent state\n",
    "    citations_with_cited_state = citations_for_cited_join.join(patent_states)\n",
    "    # Result: (cited_patent, (citing_patent, cited_state))\n",
    "    \n",
    "    print(f\"Citations with cited state: {citations_with_cited_state.count()}\")\n",
    "    citations_with_cited_state.cache()\n",
    "    \n",
    "    # Transform to (citing_patent, (cited_patent, cited_state)) for next join\n",
    "    citations_citing_key = citations_with_cited_state.map(\n",
    "        lambda x: (x[1][0], (x[0], x[1][1]))\n",
    "    )\n",
    "    \n",
    "    # Join with patent states to get citing patent state\n",
    "    full_citation_data = citations_citing_key.join(patent_states)\n",
    "    # Result: (citing_patent, ((cited_patent, cited_state), citing_state))\n",
    "    \n",
    "    print(f\"Full citation data: {full_citation_data.count()}\")\n",
    "    full_citation_data.cache()\n",
    "    \n",
    "    print(\"Sample full citation data:\")\n",
    "    sample_data = full_citation_data.take(5)\n",
    "    for item in sample_data:\n",
    "        citing = item[0]\n",
    "        cited = item[1][0][0]\n",
    "        cited_state = item[1][0][1]\n",
    "        citing_state = item[1][1]\n",
    "        print(f\"Citing: {citing} ({citing_state}) -> Cited: {cited} ({cited_state})\")\n",
    "    \n",
    "    # Filter for same-state citations and count per patent\n",
    "    same_state_citations = full_citation_data.filter(\n",
    "        lambda x: x[1][0][1] == x[1][1]  # cited_state == citing_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Same-state citations: {same_state_citations.count()}\")\n",
    "    \n",
    "    # Count same-state citations per citing patent\n",
    "    same_state_counts = (same_state_citations\n",
    "                        .map(lambda x: (x[0], 1))  # (citing_patent, 1)\n",
    "                        .reduceByKey(operator.add))  # Sum up counts\n",
    "    \n",
    "    print(f\"Patents with same-state citations: {same_state_counts.count()}\")\n",
    "    same_state_counts.cache()\n",
    "    \n",
    "    print(\"Sample same-state counts:\")\n",
    "    print(same_state_counts.take(10))\n",
    "    \n",
    "    # Join counts back with full patent data\n",
    "    # patents_parsed structure: (patent_id, (state, full_data))\n",
    "    patents_with_counts = patents_parsed.leftOuterJoin(same_state_counts)\n",
    "    # Result: (patent_id, ((state, full_data), count_or_None))\n",
    "    \n",
    "    # Create final result dictionary\n",
    "    def create_result_tuple(item):\n",
    "        patent_id = item[0]\n",
    "        state = item[1][0][0]\n",
    "        full_data = item[1][0][1]\n",
    "        count = item[1][1] if item[1][1] is not None else 0\n",
    "        \n",
    "        # Return (patent_id, (state, count, full_data))\n",
    "        return (patent_id, (state, count, full_data))\n",
    "    \n",
    "    result_rdd = patents_with_counts.map(create_result_tuple)\n",
    "    \n",
    "    # Convert to dictionary and get top 10\n",
    "    # First, filter for patents with same-state citations > 0\n",
    "    patents_with_same_state = result_rdd.filter(lambda x: x[1][1] > 0)\n",
    "    \n",
    "    # Sort by count (descending) and take top 10\n",
    "    top_10 = (patents_with_same_state\n",
    "             .map(lambda x: (x[1][1], x))  # (count, full_record) for sorting\n",
    "             .sortByKey(False)  # Sort by count descending\n",
    "             .map(lambda x: x[1])  # Extract back the full record\n",
    "             .take(10))\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result_dict = {}\n",
    "    for patent_id, (state, count, full_data) in top_10:\n",
    "        result_dict[patent_id] = (state, count, full_data)\n",
    "    \n",
    "    return result_dict, top_10, full_citation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RUNNING WITH SAMPLE DATA\n",
      "==================================================\n",
      "Using 25.0% sample of the data...\n",
      "Parsed citations: 4131964\n",
      "US patents with state info: 445835\n",
      "Sample patent states:\n",
      "[(3070803, 'IL'), (3070804, 'OH'), (3070807, 'OH'), (3070810, 'IL'), (3070814, 'MN')]\n",
      "Citations with cited state: 577741\n",
      "Full citation data: 107682\n",
      "Sample full citation data:\n",
      "Citing: 4485657 (MI) -> Cited: 3818736 (IL)\n",
      "Citing: 4485657 (MI) -> Cited: 3982415 (MI)\n",
      "Citing: 4455558 (PA) -> Cited: 3550148 (PA)\n",
      "Citing: 4487154 (WA) -> Cited: 3489998 (AL)\n",
      "Citing: 5746431 (SC) -> Cited: 3492000 (MD)\n",
      "Same-state citations: 23142\n",
      "Patents with same-state citations: 20257\n",
      "Sample same-state counts:\n",
      "[(4485657, 1), (4455558, 1), (4013517, 1), (3911052, 1), (4536240, 1), (4487550, 2), (4482462, 1), (5009295, 2), (5058462, 1), (4134966, 2)]\n",
      "\n",
      "Top 10 patents with most same-state citations (SAMPLE):\n",
      "Patent ID | State | Same-State Citations\n",
      "---------------------------------------------\n",
      " 5936426 | CA    |               10\n",
      " 5672153 | CA    |                9\n",
      " 5879349 | CA    |                9\n",
      " 5440221 | TX    |                8\n",
      " 5970240 | CA    |                7\n",
      " 5709278 | TX    |                7\n",
      " 5726482 | CA    |                7\n",
      " 5698992 | CA    |                6\n",
      " 5385284 | MI    |                6\n",
      " 5729152 | CA    |                6\n"
     ]
    }
   ],
   "source": [
    "# Run the solution with sample data first\n",
    "print(\"=\" * 50)\n",
    "print(\"RUNNING WITH SAMPLE DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sample_result_dict, sample_top_10, sample_full_citation_data = solve_patent_problem(use_sample=True)\n",
    "\n",
    "print(f\"\\nTop 10 patents with most same-state citations (SAMPLE):\")\n",
    "print(\"Patent ID | State | Same-State Citations\")\n",
    "print(\"-\" * 45)\n",
    "for patent_id, (state, count, full_data) in sample_top_10:\n",
    "    print(f\"{patent_id:8} | {state:5} | {count:16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification for top patent from sample: 5936426\n",
      "Total citations by patent 5936426: 13\n",
      "Same-state citations: 10\n"
     ]
    }
   ],
   "source": [
    "# Verify one result from sample\n",
    "if sample_top_10:\n",
    "    print(f\"\\nVerification for top patent from sample: {sample_top_10[0][0]}\")\n",
    "    top_patent_id = sample_top_10[0][0]\n",
    "    \n",
    "    # Count all citations by this patent using the returned RDD\n",
    "    all_citations_by_top = sample_full_citation_data.filter(lambda x: x[0] == top_patent_id)\n",
    "    total_citations = all_citations_by_top.count()\n",
    "    \n",
    "    # Count same-state citations\n",
    "    same_state_by_top = all_citations_by_top.filter(\n",
    "        lambda x: x[1][0][1] == x[1][1]\n",
    "    )\n",
    "    same_state_count = same_state_by_top.count()\n",
    "    \n",
    "    print(f\"Total citations by patent {top_patent_id}: {total_citations}\")\n",
    "    print(f\"Same-state citations: {same_state_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING WITH FULL DATA\n",
      "==================================================\n",
      "Using full dataset...\n",
      "Parsed citations: 16522438\n",
      "US patents with state info: 1784989\n",
      "Sample patent states:\n",
      "[(3070802, 'TX'), (3070803, 'IL'), (3070804, 'OH'), (3070805, 'CA'), (3070806, 'PA')]\n",
      "Citations with cited state: 9259246\n",
      "Full citation data: 6920796\n",
      "Sample full citation data:\n",
      "Citing: 4325814 (NJ) -> Cited: 3364136 (NJ)\n",
      "Citing: 4325814 (NJ) -> Cited: 3894934 (NJ)\n",
      "Citing: 4325814 (NJ) -> Cited: 3808121 (NJ)\n",
      "Citing: 5905860 (UT) -> Cited: 5103476 (VA)\n",
      "Citing: 5905860 (UT) -> Cited: 4870568 (MA)\n",
      "Same-state citations: 1488330\n",
      "Patents with same-state citations: 571919\n",
      "Sample same-state counts:\n",
      "[(4325814, 3), (5905860, 3), (4798725, 3), (4209855, 8), (5969823, 2), (4980702, 2), (5783433, 1), (5201118, 2), (5455989, 4), (4962447, 1)]\n",
      "\\nTop 10 patents with most same-state citations (FULL DATA):\n",
      "Patent ID | State | Same-State Citations\n",
      "---------------------------------------------\n",
      " 5959466 | CA    |              125\n",
      " 5983822 | TX    |              103\n",
      " 6008204 | CA    |              100\n",
      " 5952345 | CA    |               98\n",
      " 5958954 | CA    |               96\n",
      " 5998655 | CA    |               96\n",
      " 5936426 | CA    |               94\n",
      " 5739256 | CA    |               90\n",
      " 5978329 | CA    |               90\n",
      " 5980517 | CA    |               90\n",
      "\\nResult dictionary contains 10 entries\n",
      "Sample entries from result dictionary:\n",
      "Patent 5959466: State=CA, Count=125\n",
      "  Full data preview: ['5959466', '1999', '14515', '1997', '\"US\"']...\n",
      "\n",
      "Patent 5983822: State=TX, Count=103\n",
      "  Full data preview: ['5983822', '1999', '14564', '1998', '\"US\"']...\n",
      "\n",
      "Patent 6008204: State=CA, Count=100\n",
      "  Full data preview: ['6008204', '1999', '14606', '1998', '\"US\"']...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run with full data (uncomment to run)\n",
    "\n",
    "print(\"RUNNING WITH FULL DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "full_result_dict, full_top_10, full_citation_data_rdd = solve_patent_problem(use_sample=False)\n",
    "\n",
    "print(f\"\\\\nTop 10 patents with most same-state citations (FULL DATA):\")\n",
    "print(\"Patent ID | State | Same-State Citations\")\n",
    "print(\"-\" * 45)\n",
    "for patent_id, (state, count, full_data) in full_top_10:\n",
    "    print(f\"{patent_id:8} | {state:5} | {count:16}\")\n",
    "\n",
    "# Display the result dictionary structure\n",
    "print(f\"\\\\nResult dictionary contains {len(full_result_dict)} entries\")\n",
    "print(\"Sample entries from result dictionary:\")\n",
    "for i, (patent_id, (state, count, full_data)) in enumerate(list(full_result_dict.items())[:3]):\n",
    "    print(f\"Patent {patent_id}: State={state}, Count={count}\")\n",
    "    print(f\"  Full data preview: {full_data[:5]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up cached RDDs\n",
    "def cleanup_cache():\n",
    "    \"\"\"Clean up cached RDDs to free memory\"\"\"\n",
    "    try:\n",
    "        citations_parsed.unpersist()\n",
    "        patents_parsed.unpersist() \n",
    "        patent_states.unpersist()\n",
    "        citations_with_cited_state.unpersist()\n",
    "        full_citation_data.unpersist()\n",
    "        same_state_counts.unpersist()\n",
    "        print(\"Cache cleaned up successfully\")\n",
    "    except:\n",
    "        print(\"Some RDDs may not have been cached yet\")\n",
    "\n",
    "print(f\"\\nSolution completed! Call cleanup_cache() to free memory.\")\n",
    "print(\"Uncomment the full data section above to run on complete dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
